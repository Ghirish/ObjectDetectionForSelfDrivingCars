{"cells":[{"cell_type":"markdown","metadata":{"id":"uxWDncyvryi6"},"source":["This week, we'll be delving right into the projects. \n","\n","You and your group are going to build an AI tool that can help self-driving cars see. \n","\n","It's like this!! (Click on the image!)\n","\n","[\u003cimg src=\"https://i.ytimg.com/vi/2lxO_0FMalY/maxresdefault.jpg\" width=\"500\"/\u003e](https://www.youtube.com/watch?v=9ydhDQaLAqM)"]},{"cell_type":"markdown","metadata":{"id":"7WMqegZ_nVhd"},"source":["In this notebook we'll be:\n","1.   Understanding Object Detection for Self-driving cars\n","2.   Understanding our dataset\n","3.   Understanding and building Neural Networks\n","4.   Applying Neural Networks to Recognizing Vehicles\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6810,"status":"ok","timestamp":1656733726408,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"847Nj57ZekeU","outputId":"947df2e8-414a-42ae-d339-4265b574b35d"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow version: 2.8.2\n"]}],"source":["#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n","import os\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","\n","print(\"TensorFlow version: {}\".format(tf.__version__))\n","\n","# Load data\n","def load_cifar10():\n","  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = cifar10.load_data()\n","  y_train_cifar = y_train_cifar.squeeze()\n","  y_test_cifar = y_test_cifar.squeeze()\n","  return (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar)\n","\n","# CIFAR100 classes\n","idx_to_class = ['background', 'car', 'truck']\n","\n","# Construct vehicle dataset from CIFAR10\n","def construct_vehicle_dataset(data, labels, images_per_class, label_car=1, label_truck=9):\n","  mask_car = labels == label_car\n","  mask_truck = labels == label_truck\n","\n","  mask_vehicles = mask_car | mask_truck\n","  mask_background = np.invert(mask_vehicles)\n","  \n","  data_car = data[mask_car]\n","  data_truck = data[mask_truck]\n","  data_background = data[mask_background][:images_per_class]\n","\n","  new_data = np.vstack((data_background, data_car, data_truck))\n","  new_labels = np.repeat(np.array([0, 1, 2]), images_per_class, axis=0)\n","  \n","  return new_data, new_labels\n","\n","def load_vehicle_dataset():\n","  (x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = load_cifar10()\n","  x_train, y_train = construct_vehicle_dataset(x_train_cifar, y_train_cifar, 5000)\n","  x_test, y_test = construct_vehicle_dataset(x_test_cifar, y_test_cifar, 1000)\n","  return (x_train, y_train), (x_test, y_test)\n","\n","# Helper functions\n","\n","# plotting\n","def plot_one_image(data, labels = [], index = None, image_shape = None):\n","  '''\n","  if data is a single image, display that image\n","\n","  if data is a 4d stack of images, display that image\n","  '''\n","  ### cv2.imshow('image', data)    \n","  num_dims   = len(data.shape)\n","  num_labels = len(labels)\n","  if image_shape is not None:\n","    target_shape = image_shape\n","  else:\n","    target_shape = (32, 32, 3)\n","  # reshape data if necessary\n","  if num_dims == 1:\n","    data = data.reshape(target_shape)\n","  if num_dims == 2:\n","    data = data.reshape(np.vstack[-1, image_shape])\n","  num_dims   = len(data.shape)\n","\n","  # check if single or multiple images\n","  if num_dims == 3:\n","    if num_labels \u003e 1:\n","      print('Multiple labels does not make sense for single image.')\n","      return\n","\n","    label = labels      \n","    if num_labels == 0:\n","      label = ''\n","    image = data\n","\n","  if num_dims == 4:\n","    image = data[index, :]\n","    label = labels[index]\n","\n","  # plot image of interest\n","  print('Label: %s'%label)\n","  plt.imshow(image)\n","  plt.show()\n","\n","def model_to_string(model):\n","  import re\n","  stringlist = []\n","  model.summary(print_fn=lambda x: stringlist.append(x))\n","  sms = \"\\n\".join(stringlist)\n","  sms = re.sub('_\\d\\d\\d','', sms)\n","  sms = re.sub('_\\d\\d','', sms)\n","  sms = re.sub('_\\d','', sms)  \n","  return sms\n","\n","def normalize(data):\n","  # CIFAR100 mean (0.4914, 0.4822, 0.4465) std (0.2023, 0.1994, 0.2010)\n","  return (data/255-np.array((0.4914, 0.4822, 0.4465))) / np.array((0.2023, 0.1994, 0.2010))\n","\n","def label_to_onehot(labels):\n","  final_labels = np.zeros((len(labels), 3))\n","  for i in range(len(labels)):\n","    label = labels[i]\n","    if label == 0:\n","      final_labels[i,:] = np.array([1, 0, 0])\n","    if label == 1:\n","      final_labels[i,:] = np.array([0, 1, 0])\n","    if label == 2:\n","      final_labels[i,:] = np.array([0, 0, 1])\n","  return final_labels\n","\n","def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n","  # i'm sorry for this function's code. i am so sorry. \n","  history = history.history\n","  history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","  history = pd.DataFrame.from_dict(history)\n","\n","  best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","  if not ax:\n","    f, ax = plt.subplots(1,1)\n","  sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","  sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","  ax.axhline(0.333, linestyle = '--',color='red', label = 'Chance')\n","  ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","  ax.legend(loc = 1)    \n","  ax.set_ylim([0.01, 1])\n","\n","  ax.set_xlabel(xlabel)\n","  ax.set_ylabel('Accuracy (Fraction)')\n","  \n","  plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Am2Oe87hihZA"},"source":["# Milestone 1. Understanding our task"]},{"cell_type":"markdown","metadata":{"id":"M6ULauRiUnva"},"source":["## Exercise (Discussion) | Self-driving cars"]},{"cell_type":"markdown","metadata":{"id":"FL0PZLszVLsc"},"source":["We'll start by understanding our problem, identifying:\n","* What are potential benefits of self-driving cars? \n","* How do self-driving cars work? \n","* How do self-driving cars see? "]},{"cell_type":"markdown","metadata":{"id":"iqm6BqAPwPFI"},"source":["## Exercise (Discussion) | Object Detection"]},{"cell_type":"markdown","metadata":{"id":"ryH-OYB7wdOX"},"source":["\n","- Given an input image, what is the output of the object detection task?\n","\n","\n","- Can you break this problem into some subtasks?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eIOd_yqVVxom"},"source":["Today, we'll first start from building a image classifier which can recognize cars."]},{"cell_type":"markdown","metadata":{"id":"5Lb-mORcVaMI"},"source":["# Milestone 2. Understanding our data"]},{"cell_type":"markdown","metadata":{"id":"g94jZ8bIDvvh"},"source":["## Activity 1. What data do we have?"]},{"cell_type":"markdown","metadata":{"id":"v1OYUQBoqAh1"},"source":["One commonly used dataset for object recognition is CIFAR10. There are 10 classes in CIFAR10, including airplane, car, bird, cat, deer, dog, frog, horse, ship, truck. \n","\n","As we are trying to build a image classifier for self-driving cars, detecting cars is more of interest to us. \n","\n","Therefore, here we use a vehicle dataset, which contains the images in the car and truck categories, as well as some randomly chosen images from other categories in the CIFAR10 dataset.\n","\n","We use `load_vehicle_dataset()` to load the images in both the training set and the test set.\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6372,"status":"ok","timestamp":1656733732777,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"0qP5mLh7U00D","outputId":"9bddf50b-64ef-40eb-b043-c0da81a9219e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n"]}],"source":["(x_train, y_train), (x_test, y_test) = load_vehicle_dataset()"]},{"cell_type":"markdown","metadata":{"id":"rh4rmliVDaon"},"source":["Here, `x` contains the images and `y` contains the corresponding class labels. \n","\n","Let's first get a better understanding of the dataset by looking into the labels."]},{"cell_type":"markdown","metadata":{"id":"vUqNQ0hnCO6v"},"source":["### Exercise 1"]},{"cell_type":"markdown","metadata":{"id":"yQK_cWxFD6Ix"},"source":["`y_train` and `y_test` are 2 numpy arrays of our images' labels."]},{"cell_type":"markdown","metadata":{"id":"CZ9fBKusGXqY"},"source":["The shape of a numpy array is stored in the `shape` attribute, so we can check the shape of the training set label by `y_train.shape`."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1656733732778,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"m5dlllnKEi96","outputId":"d416075b-af02-406a-e8fb-6bc2f70300c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Our labels are stored as \u003cclass 'numpy.ndarray'\u003e in Python\n","The label vector of the training set has dimensions of (15000, )\n","The label vector of the test set has dimensions of (3000, )\n"]}],"source":["print('Our labels are stored as %s in Python' % type(y_train))\n","print('The label vector of the training set has dimensions of (%d, )' % y_train.shape)\n","print('The label vector of the test set has dimensions of (%d, )' % y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"AYKKmeCl9_rl"},"source":["Each object catogory is represented in a number as the label in the `y` vectors. \n","\n","Class names have been saved in the list `idx_to_class`, where the indices are the labels and the elements are class names. Eg. `idx_to_class[1]` is `car`, this means each `car` image has a label `1` in the `y` vector.\n","\n","You can print the whole list to check the 3 classes we have in this dataset."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1656733732778,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"gjFAIHHoAzLk","outputId":"6e964b99-3d41-4241-e1e7-0e854bc25f16"},"outputs":[{"name":"stdout","output_type":"stream","text":["['background', 'car', 'truck']\n"]}],"source":["### YOUR CODE HERE\n","print(idx_to_class)\n","### END CODE"]},{"cell_type":"markdown","metadata":{"id":"rmE9b7zECu36"},"source":["### Exercise 2"]},{"cell_type":"markdown","metadata":{"id":"l_N8hpXYIpT_"},"source":["We also want to know how many images we have in each class. The `Counter` class in the `collections` package can count the occurrence of different elements for us. For example:\n","\n","```\n","l = [1, 2, 3, 3, 4, 5, 5, 5]\n","counter = collections.Counter(l)\n","print(counter)\n","```\n","\n","We can get:\n","```\n","Counter({5: 3, 3: 2, 1: 1, 2: 1, 4: 1})\n","```\n","\n","Try to use this to check the number of images we have in each object category."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1656733732778,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"jBl0ePbHE0s6","outputId":"7c8095be-8241-4a99-9c08-1e0637db3b03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Counter({0: 5000, 1: 5000, 2: 5000})\n","Counter({0: 1000, 1: 1000, 2: 1000})\n"]}],"source":["import collections\n","\n","### YOUR CODE HERE\n","cnt_train = collections.Counter(y_train)\n","cnt_test = collections.Counter(y_test)\n","\n","print(cnt_train)\n","print(cnt_test)\n","\n","### END CODE"]},{"cell_type":"markdown","metadata":{"id":"JBHUX917wkeo"},"source":["## Activity 2. What does our data look like? "]},{"cell_type":"markdown","metadata":{"id":"9uA4zJPqF1oC"},"source":["Next, let's take a look at the images in the dataset."]},{"cell_type":"markdown","metadata":{"id":"86FTqK8JwDjk"},"source":["### Exercise 3"]},{"cell_type":"markdown","metadata":{"id":"qDEDVcREGGfY"},"source":["The images in the training and test sets are stored as numpy arrays in `x_train` and `x_test` respectively. \n","\n","Can you get the shape of these 2 arrays as what we did on the labels?"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1656733732778,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"AP74pX8NHlyM","outputId":"bbeca716-29e9-4696-d892-02348be3b855"},"outputs":[{"name":"stdout","output_type":"stream","text":["(15000, 32, 32, 3)\n","(3000, 32, 32, 3)\n"]}],"source":["### YOUR CODE HERE\n","print(x_train.shape)\n","print(x_test.shape)\n","### END CODE"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1656733733157,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"6iYXd67jIRsG","outputId":"2db1f395-3610-48a7-8904-247c85cab754"},"outputs":[{"name":"stdout","output_type":"stream","text":["Yes! Dimension_0 is the number of images.\n","Yes! Dimension_1 is the height of the image.\n","Yes! Dimension_2 is the width of the image.\n","Yes! Dimension_3 stands for 3 colors - (r,g,b).\n"]}],"source":["#@title What does image shape represent? { display-mode: \"form\" }\n","\n","#@markdown What does the bold number (**15000**, 32, 32, 3) represent? \n","Dimension_0  = \"number of images\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n","\n","#@markdown What does the bold number (15000, **32**, 32, 3) represent? \n","Dimension_1  = \"image height\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n","  \n","#@markdown What does the bold number (15000, 32, **32**, 3) represent? \n","Dimension_2  = \"image width\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n","\n","#@markdown What does the bold number (15000, 32, 32, **3**) represent? \n","Dimension_3  = \"number of colors\" #@param [\"number of images\", \"image width\", \"image height\",\"number of colors\",\"fill in\"]\n","\n","if Dimension_0 == 'number of images':\n","  print(\"Yes! Dimension_0 is the number of images.\")\n","else:\n","  print(\"Try again for Dimension_0!\")\n","\n","if Dimension_1 == 'image height':\n","  print(\"Yes! Dimension_1 is the height of the image.\")\n","else:\n","  print(\"Try again for Dimension_1!\")\n","\n","if Dimension_2 == 'image width':\n","  print(\"Yes! Dimension_2 is the width of the image.\")\n","else:\n","  print(\"Try again for Dimension_2!\")\n","  \n","if Dimension_3 == 'number of colors':\n","  print(\"Yes! Dimension_3 stands for 3 colors - (r,g,b).\")\n","else:\n","  print(\"Try again for Dimension_3!\")\n"]},{"cell_type":"markdown","metadata":{"id":"_WxXax6-FkMj"},"source":["### Exercise 4\n","\n","Remember our `plot_one_image` function from last week? We'll use that with our data to view our images! Let's see a single image. \n","\n","`plot_one_image` can take in either one image or many images. \n","\n","```\n","plot_one_image(data, labels)\n","```\n","\n","where:\n","* `data`: 1 or more images in one array\n","* `labels`: the labels corresponding to the images in a list\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1656733733570,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"HJibNL7CzXrl","outputId":"483525d9-7d12-4757-e589-1bbe777fcb93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label: ['car']\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# plot a SINGLE image\n","### YOUR CODE HERE\n","data = x_train[7000]\n","labels = [idx_to_class[y_train[7000]]]\n","data = plot_one_image(data, labels)\n","### END CODE"]},{"cell_type":"markdown","metadata":{"id":"0yuxN0RkihuB"},"source":["Next, let's build an classifier using neural networks!"]},{"cell_type":"markdown","metadata":{"id":"3AJzmg0drIYP"},"source":["# Milestone 3. Understanding and building Neural Networks (Perceptron)"]},{"cell_type":"markdown","metadata":{"id":"SYqvCKWpKfRM"},"source":["### What are neural networks?"]},{"cell_type":"markdown","metadata":{"id":"qA1Rc_u3KoJT"},"source":["Just as we went over last week, neural networks look something like this: \n","![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n"]},{"cell_type":"markdown","metadata":{"id":"3Q9S6SDcM8N9"},"source":["Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. \n","\n","**In terms of this problem, what do each of the 4 blue neurons correspond to?**"]},{"cell_type":"markdown","metadata":{"id":"0dik5yhBOERG"},"source":["## Activity 1. Building networks"]},{"cell_type":"markdown","metadata":{"id":"E--8mjToZYBp"},"source":["To build neural networks in Python, we use the packages known as `tensorflow` and `keras`. Let's learn how to build and use these networks!"]},{"cell_type":"markdown","metadata":{"id":"G8PrEOTbhgNN"},"source":["Tensorflow calls the various machine learning algorithms that it uses 'models'.  These 'models' are 'learning machines.''\n","\n","1. We **teach** models by **training** them on **data**. \n","2. We **use** models to **predict** things. \n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1656733733571,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"cqFAnQCxsgRm"},"outputs":[],"source":["# grab tools from our tensorflow and keras toolboxes!\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","from tensorflow.keras import optimizers"]},{"cell_type":"markdown","metadata":{"id":"cPOqTta1sb6e"},"source":["Before we train the model or use it to predict something, we have to **create** the model. "]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":385,"status":"ok","timestamp":1656733733947,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"Yus22AQpsqMH"},"outputs":[],"source":["# create our model by specifying and compiling it\n","model = Sequential()\n","model.add(Dense(4, input_shape=(3,),activation = 'relu'))\n","model.add(Dense(1, activation = 'linear'))\n","model.compile(loss='mean_squared_error',\n","                optimizer='adam',\n","                metrics=['mean_squared_error'])"]},{"cell_type":"markdown","metadata":{"id":"LG3k7_983L1s"},"source":["The things you'll want to pay most attention to as we go over how to build networks are: \n","1. The number of neurons\n","2. The activation of the neurons\n","3. The losses and metrics\n","\n","Everything else will work with the default settings!"]},{"cell_type":"markdown","metadata":{"id":"781M4IyhssuA"},"source":["Let's walk though what each of these lines of code means!\n","\n","**1. Specify model**\n","\n","```\n","model = Sequential()\n","```\n","In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n","\n","\n","**2. Add layers to the network**\n","```\n","model.add(Dense(4,input_shape = (3,), activation = 'sigmoid'))\n","```\n","In this code, we `add` a `layer` of neurons to our network. \n","\n","This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n","\n","We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n","\n","```\n","model.add(Dense(1, activation = 'linear'))\n","```\n","This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n","\n","**3. Turn the model on by compiling it** \n","\n","After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics). Don't worry too much about what this means! Just know that this is necessary. \n","\n","```\n","model.compile(loss='mean_squared_error',\n","optimizer = 'adam',\n","metrics = ['mean_squared_error'])\n","  ```"]},{"cell_type":"markdown","metadata":{"id":"toYjQUOVtKDT"},"source":["Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n","\n","```\n","model.fit(x, y)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"-aozkfBxtWa7"},"source":["To use the model, you can use it to predict something with:\n","```\n","y = model.predict_classes(x)\n","```\n","\n","You can actually use the model before you even train it! It just won't perform very well. "]},{"cell_type":"markdown","metadata":{"id":"Wlnni4nPyCA3"},"source":["### Exercise (Coding): A 2-Layer Model\n"]},{"cell_type":"markdown","metadata":{"id":"xP5Z9cEMyBpM"},"source":["\n","We're going to build this model: \n","\n","![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"]},{"cell_type":"markdown","metadata":{"id":"jxN_eHSoyBcF"},"source":["This network can be described as: \n","* Input Layer: 3\n","* Layer 1 (Hidden): 4 neurons that are activated by `'relu'`\n","* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n","\n","\n","We also want to compile the model with\n","`loss = 'categorical_crossentropy'`"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656733733948,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"d4rDgysgFtsC"},"outputs":[],"source":["# grab tools from our tensorflow and keras toolboxes!\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","from tensorflow.keras import optimizers"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":156,"status":"ok","timestamp":1656734132814,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"-zgA-wPfvCyK"},"outputs":[],"source":["### YOUR CODE HERE:\n","model_1_answer = Sequential()\n","model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n","model_1_answer.add(Dense(2, activation = 'softmax'))\n","model_1_answer.compile(loss='categorical_crossentropy',\n","optimizer = 'adam', \n","metrics = ['accuracy'])\n","model_1 = model_1_answer\n","### END CODE"]},{"cell_type":"code","execution_count":22,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1656734135967,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"IH2UGOK4vuZ4","outputId":"c52b3232-e816-4905-ac6c-9e2f099c5aa6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Good job! Your model worked\n"]}],"source":["#@title Run this to test if your model is right!\n","model_1_answer = Sequential()\n","model_1_answer.add(Dense(4, input_shape = (3,), activation = 'relu'))\n","model_1_answer.add(Dense(2, activation = 'softmax'))\n","model_1_answer.compile(loss='categorical_crossentropy',\n","optimizer = 'adam', \n","metrics = ['accuracy'])\n","\n","if model_to_string(model_1) == model_to_string(model_1_answer):\n","  print('Good job! Your model worked')\n","else: \n","  print('Please check your code again!')"]},{"cell_type":"markdown","metadata":{"id":"tyLV1oHjT62K"},"source":["# Milestone 4. Applying Neural Networks to Recognizing Vehicles\n"]},{"cell_type":"markdown","metadata":{"id":"hBp4yqqoJF65"},"source":["## Instructor-Led Discussion: Model Architecture"]},{"cell_type":"markdown","metadata":{"id":"PD3Z0QamJF68"},"source":["\n","In our problem, we are given `images` of shape `(32, 32, 3)`, each assigned to one of 3 labels: car, truck, others. We want to identify the key things that we need to design our network. \n","\n","In your group, discuss: \n","\n","* What are our inputs?\n","* What is/are our outputs?\n","* How could this look in a neural network diagram?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"K-7tm6ZlJF7G"},"source":["## Activity 1. Building our custom neural network"]},{"cell_type":"markdown","metadata":{"id":"e8pozxKuJF7I"},"source":["### Key Points "]},{"cell_type":"markdown","metadata":{"id":"UN4Pyw4qJF7N"},"source":["We will build a simple 2-layer network for our first model!\n","\n","\n","For our model, we have as our layers: \n","* Input Layer:  However many inputs there are!\n","* Layer 1 (Hidden): 128 neurons that are activated by `'relu'`\n","* Layer 2 (Output): 3 neurons (1 per possible predicted class) that should have an appropriate activation. \n","* We will compile with the `optimizers.SGD(learning_rate=1e-3, momentum=0.9)` optimizer\n","\n","As a hint for the output activation and the compilation loss, we know that:\n","* Binary classification problems require an output activation of `'sigmoid'` and a loss of `'binary_cross_entropy'`\n","* Multi-class classification problems require an output activation of `'softmax'` and a loss of `'categorical_crossentropy'`\n","* Linear regression problems require an output activation of `'linear'` and a loss of `'mean_squared_error'`\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LzFTOYMiJF7Q"},"source":["###Build Your Model\n","\n","Remember the transformation you need to apply to your input (hint: flattening) in order to make it work with a multi-layer perceptron!"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1656734205098,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"ZJUSGm_oJF7h"},"outputs":[],"source":["perceptron = Sequential()\n","perceptron.add(Flatten(input_shape = (32, 32, 3)))\n","perceptron.add(Dense(units = 128, activation = 'relu'))\n","perceptron.add(Dense(units = 3, activation = 'softmax'))\n","    \n","perceptron.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.SGD(learning_rate=1e-3, momentum=0.9),\n","              metrics=['accuracy'])\n","### END CODE"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1656734206305,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"9i-xfhnaJF7q","outputId":"f6a280c4-40b7-44d4-d2ce-f6f55d1a10c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Good job, you specified it correctly!\n"]}],"source":["#@title Run this to test if your model is right! { display-mode: \"form\" }\n","perceptron_answer = Sequential()\n","perceptron_answer.add(Flatten(input_shape = (32, 32, 3)))\n","perceptron_answer.add(Dense(units = 128, activation = 'relu'))\n","perceptron_answer.add(Dense(units = 3, activation = 'softmax'))\n","    \n","perceptron_answer.compile(loss='categorical_crossentropy',\n","              optimizer=optimizers.SGD(learning_rate=1e-3, momentum=0.9),\n","              metrics=['accuracy'])\n","\n","if model_to_string(perceptron) == model_to_string(perceptron_answer):\n","  print('Good job, you specified it correctly!')\n","else: \n","  print('Please check your code again!')"]},{"cell_type":"markdown","metadata":{"id":"nayBlbHmj4Ii"},"source":["### Exercise (Coding)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AItvQJE5NY0H"},"source":["Let's now train our perceptron on images from the train data! \n","\n","Unlike the models that we used in sklearn, our neural networks are pretty finnicky. Their performance depends a lot on *how much* they train. As we'll see, they usually get better with more training BUT actually can get worse with too much training. With too much training, our model can get overconfident in its abilities with the training manual (overfitting), and so doesn't actually think (generalize) when it is tested. \n","\n","The extra options in our `fit()` function pertain to how the neural networks train. Don't worry too much about the extra options, what really matters for us is that the right data is specified.\n","\n","To use `fit`, we use the following code:\n","```\n","history = perceptron.fit(train_data, train_labels, epochs = 10, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","```\n","What are all these options?\n","* `epochs`: how many times the model trains on the entire data set\n","* `shuffle`: mixes the training dataset so the model pays better attention to the data and learns better while training\n","* `validation_data`: we request that our model tests itself on the `test_data` after every epoch. Since our model is finnicky, instead of testing our model at the end of the training, we test it throughout. \n","\n"," `history` gives us a data structure which allows us to plot the training and validation accuracy over time.\n","\n","We have one more option too:\n","* `callbacks`: With a custom command, we tell our model to save the best version of itself to a model file called `model.h5`. \n","\n","\n","Let's try this out!\n","\n","**Specifically, load in the training and testing data and then train your MLP model.**\n"]},{"cell_type":"markdown","metadata":{"id":"s41zgK7lFQtT"},"source":["Before training the model, we need to preprocess the data for better training. \n","Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. We have implemented this in the `normalize(input_data)` for you.\n","\n","Besides, we need to convert the label for each image into a one-hot vector, which means, for example, we represent label 2 (truck) as a vector `[0, 0, 1]`, so that the model output can be directly compared with the data label. This has been implemented in the `label_to_onehot(labels)` function."]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1656734211087,"user":{"displayName":"Ghirish","userId":"10176880632033865315"},"user_tz":420},"id":"-tjgTdXv6Kh7"},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"-PeIseTjM7uG"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","469/469 [==============================] - 4s 6ms/step - loss: 0.8833 - accuracy: 0.6285 - val_loss: 0.7838 - val_accuracy: 0.6663\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6683 - accuracy: 0.7241 - val_loss: 0.7308 - val_accuracy: 0.6927\n","Epoch 3/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.5978 - accuracy: 0.7599 - val_loss: 0.7101 - val_accuracy: 0.7053\n","Epoch 4/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5485 - accuracy: 0.7813 - val_loss: 0.7010 - val_accuracy: 0.7097\n","Epoch 5/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.5027 - accuracy: 0.7988 - val_loss: 0.7253 - val_accuracy: 0.7100\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4623 - accuracy: 0.8221 - val_loss: 0.7688 - val_accuracy: 0.7003\n","Epoch 7/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.4345 - accuracy: 0.8318 - val_loss: 0.7115 - val_accuracy: 0.7177\n","Epoch 8/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3948 - accuracy: 0.8507 - val_loss: 0.7475 - val_accuracy: 0.7060\n","Epoch 9/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3706 - accuracy: 0.8613 - val_loss: 0.7473 - val_accuracy: 0.7207\n","Epoch 10/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3377 - accuracy: 0.8755 - val_loss: 0.7839 - val_accuracy: 0.7080\n","Epoch 11/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3130 - accuracy: 0.8853 - val_loss: 0.7816 - val_accuracy: 0.7200\n","Epoch 12/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2848 - accuracy: 0.8984 - val_loss: 0.7877 - val_accuracy: 0.7227\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2629 - accuracy: 0.9086 - val_loss: 0.8223 - val_accuracy: 0.7153\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2427 - accuracy: 0.9153 - val_loss: 0.8609 - val_accuracy: 0.7150\n","Epoch 15/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2211 - accuracy: 0.9241 - val_loss: 0.8473 - val_accuracy: 0.7217\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1963 - accuracy: 0.9338 - val_loss: 0.8653 - val_accuracy: 0.7223\n","Epoch 17/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1770 - accuracy: 0.9436 - val_loss: 0.9082 - val_accuracy: 0.7190\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1534 - accuracy: 0.9537 - val_loss: 0.9725 - val_accuracy: 0.7070\n","Epoch 19/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1334 - accuracy: 0.9601 - val_loss: 1.0016 - val_accuracy: 0.6957\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1255 - accuracy: 0.9653 - val_loss: 0.9754 - val_accuracy: 0.7163\n"]}],"source":["# define our monitor. Don't worry about the parameters here except for './model.h5' which is the file that our model saves to \n","monitor = ModelCheckpoint('./model.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n","\n","# Normalize the data.\n","x_train_norm = normalize(x_train)\n","x_test_norm = normalize(x_test)\n","\n","# Convert labels into one-hot numpy arrays.\n","y_train_onehot = label_to_onehot(y_train)\n","y_test_onehot = label_to_onehot(y_test)\n","\n","### YOUR CODE HERE\n","history = perceptron.fit(x_train_norm, y_train_onehot, epochs=20, validation_data=(x_test_norm, y_test_onehot), shuffle = True, callbacks = [monitor])\n","\n","### END CODE"]},{"cell_type":"markdown","metadata":{"id":"ttqZa25BVDeR"},"source":["As our model trained, it told us a few things. The most important things to us are:\n","* how accurate it was when training on the training set (reported as `acc`) \n","* how accurate it was on the test set (reported as `val_acc`)\n"]},{"cell_type":"markdown","metadata":{"id":"rsOkqi035XRE"},"source":["We can actually plot how how well our model did across epochs using the model's `history`!\n","To do this, we call:\n","```\n","plot_acc(history)\n","```\n","\n","Try `plot_acc` below!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvhyL-jJ9rKt"},"outputs":[],"source":["### YOUR CODE HERE\n","\n","### END CODE"]},{"cell_type":"markdown","metadata":{"id":"uofnvxpz-qdI"},"source":["## Instructor-Led Discussion\n","\n","Is this a good model? Does your model overfit? How do you know?"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of Student_ObjectDetection_Section1.ipynb","provenance":[{"file_id":"1F5WvF8-tXe92rIipDj4A5j1tZekseiW7","timestamp":1656214481046},{"file_id":"1KkM7fPBWT0d42cb6wcYgSuaHMgdoq2V_","timestamp":1591572398683}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}